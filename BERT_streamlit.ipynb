{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4V0+K3FP3Ga5lBkU2gR4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swarnlataaa/Generative-AI_demo/blob/main/BERT_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DOvt_jkHo5m6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiiVoe8r-2s1"
      },
      "outputs": [],
      "source": [
        " !pip install streamlit transformers spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "import spacy\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "st.title(\"Automated Compliance Checker\")\n",
        "\n",
        "# Load Spacy model for text processing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load BERT model and tokenizer for compliance checking\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "user_input = st.text_area(\"Paste your legal document here:\", height=400)\n",
        "if st.button(\"Check Compliance\"):\n",
        "    # Perform compliance check and provide suggestions\n",
        "    suggestions = check_compliance(user_input)\n",
        "    st.write(\"Compliance Status:\", suggestions)\n"
      ],
      "metadata": {
        "id": "GIS2Fnj_DUR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_compliance(text):\n",
        "    # Tokenize the text using BERT tokenizer\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    labels = torch.tensor([1]).unsqueeze(0)  # Change the label according to your criterion\n",
        "\n",
        "    # Use BERT for sequence classification\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss, logits = outputs.loss, outputs.logits\n",
        "\n",
        "    compliance_score = torch.softmax(logits, dim=1)[0][1].item()\n",
        "\n",
        "    # Analyze the document using Spacy (example for named entity recognition)\n",
        "    doc = nlp(text)\n",
        "    entities = [ent.text for ent in doc.ents]\n",
        "\n",
        "    # Provide suggestions based on the compliance score and entities found\n",
        "    if compliance_score > 0.5:\n",
        "        return \"Compliant\"\n",
        "    else:\n",
        "        suggestions = \"Non-compliant. Check these entities: \" + \", \".join(entities)\n",
        "        return suggestions\n"
      ],
      "metadata": {
        "id": "buQUAOb7DWUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !streamlit run app.py\n"
      ],
      "metadata": {
        "id": "N37GqQC3Df96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Qne4GzoDn0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}